{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML\n",
        "(started while reading Gerome's HOML)\n",
        "\n",
        "\n",
        "TODO: start doing bits revision from here:"
      ],
      "metadata": {
        "id": "gLXLCRBDgBms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Impute, transform, scale\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "\n",
        "# Make data\n",
        "m, n = 100_000, 1\n",
        "X = np.random.randn(m).reshape(-1,1)\n",
        "X -= X.min() - 1.0\n",
        "X **= 3\n",
        "X[np.random.permutation(m)[:int(m*0.1)]] = np.nan  #  0.1 = proportion of nans\n",
        "\n",
        "# Train Test Split\n",
        "Xtrain, Xtest = train_test_split(X, test_size=0.2)\n",
        "\n",
        "# Impute, Transform, Scale\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "transformer = FunctionTransformer(lambda x: x ** (1/3), inverse_func=lambda x: x**3)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Pipeline\n",
        "pl = make_pipeline(imputer, transformer, scaler)\n",
        "pl.fit(Xtrain)\n",
        "\n",
        "# Visualize\n",
        "Xtest = pl.transform(Xtest)\n",
        "plt.hist(Xtest, bins=50);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "YB_Uaxtkzgfh",
        "outputId": "e6e494eb-eed3-4421-8d19-ef7f8866bad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNtnMlU1PsN4"
      },
      "outputs": [],
      "source": [
        "\"\"\"Output dataframe\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Make sklearn output a DataFrame\n",
        "sklearn.set_config(transform_output='pandas')\n",
        "\n",
        "# Data\n",
        "X = df = pd.DataFrame({'x1': [1,2,3,1,2,3,1,2,3], 'x2': [1,1,1,2,2,2,3,3,3]})\n",
        "y = ytrue = pd.Series([1,2,3,4,5,6,7,8,9])\n",
        "\n",
        "# Scale\n",
        "X = StandardScaler().fit_transform(X)  # X is a DataFrame\n",
        "\n",
        "# Witness\n",
        "print(X.head())\n",
        "\n",
        "# Model\n",
        "md = LinearRegression().fit(X,y)\n",
        "\n",
        "# Predict\n",
        "ypred = md.predict(X)\n",
        "\n",
        "# Set back to default\n",
        "sklearn.set_config(transform_output='default')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Building a big pipeline\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "\n",
        "## Data Cleaning ###\n",
        "\n",
        "class AColumnTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        col = 'A'\n",
        "        X[col] = X[col].apply(lambda cell: int(cell))\n",
        "        return X\n",
        "\n",
        "class BColumnTransformer(BaseEstimator, TransformerMixin):\n",
        "    ...\n",
        "\n",
        "cleaning_pipeline = Pipeline([\n",
        "    ('a_column_transformer', AColumnTransformer()),\n",
        "    ('b_column_transformer', BColumnTransformer()),\n",
        "])\n",
        "#---------------------------------------------------------\n",
        "\n",
        "### Imputing Missing Values and further preprocessing ###\n",
        "\n",
        "numerical_pipeline = Pipeline([\n",
        "    ('numerical_imputer', SimpleImputer(strategy='median')),\n",
        "    ('function_transformer', FunctionTransformer(np.sqrt, validate=True)),\n",
        "    ('scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('categorical_imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('one_hot_encoder', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)),\n",
        "])\n",
        "\n",
        "### Parallelize the two pipelines ###\n",
        "\n",
        "numerical_features = ['A', 'B']\n",
        "categorical_features = ['C']\n",
        "\n",
        "imputing_pipeline = ColumnTransformer([\n",
        "    ('numerical_pipeline', numerical_pipeline, numerical_features),\n",
        "    ('categorical_pipeline', categorical_pipeline, categorical_features),\n",
        "                                      ], remainder='passthrough')\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "### Connect the two pipelines ###\n",
        "\n",
        "preprocessing_pipeline = Pipeline([\n",
        "    ('cleaning_pipeline', cleaning_pipeline),\n",
        "    ('imputing_pipeline', imputing_pipeline),\n",
        "])\n",
        "\n",
        "### Display this pipeline in a Jupyter cell ###\n",
        "preprocessing_pipeline\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "1n0q7OMJP8Jf",
        "outputId": "f38fa30e-fce4-40ff-d8d5-ebbe69c09783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('cleaning_pipeline',\n",
              "                 Pipeline(steps=[('a_column_transformer', AColumnTransformer()),\n",
              "                                 ('b_column_transformer',\n",
              "                                  BColumnTransformer())])),\n",
              "                ('imputing_pipeline',\n",
              "                 ColumnTransformer(remainder='passthrough',\n",
              "                                   transformers=[('numerical_pipeline',\n",
              "                                                  Pipeline(steps=[('numerical_imputer',\n",
              "                                                                   SimpleImputer(strategy='median')),\n",
              "                                                                  ('function_transformer',\n",
              "                                                                   FunctionTransformer(func=<ufunc 'sqrt'>,\n",
              "                                                                                       validate=True)),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['A', 'B']),\n",
              "                                                 ('categorical_pipeline',\n",
              "                                                  Pipeline(steps=[('categorical_imputer',\n",
              "                                                                   SimpleImputer(strategy='most_frequent')),\n",
              "                                                                  ('one_hot_encoder',\n",
              "                                                                   OneHotEncoder(drop='first',\n",
              "                                                                                 handle_unknown='ignore',\n",
              "                                                                                 sparse_output=False))]),\n",
              "                                                  ['C'])]))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cleaning_pipeline&#x27;,\n",
              "                 Pipeline(steps=[(&#x27;a_column_transformer&#x27;, AColumnTransformer()),\n",
              "                                 (&#x27;b_column_transformer&#x27;,\n",
              "                                  BColumnTransformer())])),\n",
              "                (&#x27;imputing_pipeline&#x27;,\n",
              "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
              "                                   transformers=[(&#x27;numerical_pipeline&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;numerical_imputer&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                                                                  (&#x27;function_transformer&#x27;,\n",
              "                                                                   FunctionTransformer(func=&lt;ufunc &#x27;sqrt&#x27;&gt;,\n",
              "                                                                                       validate=True)),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;A&#x27;, &#x27;B&#x27;]),\n",
              "                                                 (&#x27;categorical_pipeline&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;categorical_imputer&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                                  (&#x27;one_hot_encoder&#x27;,\n",
              "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
              "                                                                                 handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                                 sparse_output=False))]),\n",
              "                                                  [&#x27;C&#x27;])]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cleaning_pipeline&#x27;,\n",
              "                 Pipeline(steps=[(&#x27;a_column_transformer&#x27;, AColumnTransformer()),\n",
              "                                 (&#x27;b_column_transformer&#x27;,\n",
              "                                  BColumnTransformer())])),\n",
              "                (&#x27;imputing_pipeline&#x27;,\n",
              "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
              "                                   transformers=[(&#x27;numerical_pipeline&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;numerical_imputer&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                                                                  (&#x27;function_transformer&#x27;,\n",
              "                                                                   FunctionTransformer(func=&lt;ufunc &#x27;sqrt&#x27;&gt;,\n",
              "                                                                                       validate=True)),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;A&#x27;, &#x27;B&#x27;]),\n",
              "                                                 (&#x27;categorical_pipeline&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;categorical_imputer&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                                  (&#x27;one_hot_encoder&#x27;,\n",
              "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
              "                                                                                 handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                                 sparse_output=False))]),\n",
              "                                                  [&#x27;C&#x27;])]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cleaning_pipeline: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;a_column_transformer&#x27;, AColumnTransformer()),\n",
              "                (&#x27;b_column_transformer&#x27;, BColumnTransformer())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>AColumnTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>BColumnTransformer()</pre></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">imputing_pipeline: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
              "                  transformers=[(&#x27;numerical_pipeline&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;numerical_imputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                                                 (&#x27;function_transformer&#x27;,\n",
              "                                                  FunctionTransformer(func=&lt;ufunc &#x27;sqrt&#x27;&gt;,\n",
              "                                                                      validate=True)),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 [&#x27;A&#x27;, &#x27;B&#x27;]),\n",
              "                                (&#x27;categorical_pipeline&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;categorical_imputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                 (&#x27;one_hot_encoder&#x27;,\n",
              "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
              "                                                                handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                sparse_output=False))]),\n",
              "                                 [&#x27;C&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;A&#x27;, &#x27;B&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;ufunc &#x27;sqrt&#x27;&gt;, validate=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;C&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"One-Hot Encoding\"\"\"\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Data\n",
        "m,n = 100, 3\n",
        "X = np.random.randn(m,n).round(2)\n",
        "df = pd.DataFrame(X, columns=[\"x1\", \"x2\", \"x3\"])\n",
        "df['x2'] = np.array(['f', 'm'])[(X[:,1] >= 0).astype(int)]\n",
        "df['x3'] = pd.cut(X[:,2], bins=[-np.inf, -1, 1, np.inf], labels=[0,1,2], ordered=True)\n",
        "\n",
        "# One-Hot Encoding\n",
        "num_features = ['x1']\n",
        "cat_features = ['x2', 'x3']\n",
        "oh = OneHotEncoder(categories='auto', drop='first', sparse_output=False,\n",
        "                   handle_unknown='ignore')\n",
        "nd = oh.fit_transform(df[cat_features])\n",
        "\n",
        "# for demonstration/visualization purposes:\n",
        "df_out = pd.DataFrame(np.hstack([df[num_features], nd]),\n",
        "                      columns=['x1'] + list(oh.get_feature_names_out()))\n",
        "print(df_out.head())\n",
        "\n",
        "# this would raise an exception if handle_unknown='error': Found unknown categories ['d']\n",
        "Xnew = [['m', 2],\n",
        "        ['f', 0],\n",
        "        ['d', 3]]  # this row will be full of zeros\n",
        "nd_new = oh.transform(Xnew)\n",
        "nd_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLQ4QX32Pwvj",
        "outputId": "8c17f589-19af-4fe6-d49e-3ede2993b3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     x1  x2_m  x3_1  x3_2\n",
            "0  0.51   1.0   1.0   0.0\n",
            "1 -0.89   1.0   1.0   0.0\n",
            "2  0.63   1.0   0.0   0.0\n",
            "3  1.03   1.0   0.0   0.0\n",
            "4 -0.71   1.0   1.0   0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:202: UserWarning: Found unknown categories in columns [0, 1] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 1.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Min-Max Scaler\"\"\"\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "sklearn.set_config(transform_output='pandas')\n",
        "\n",
        "# Data\n",
        "m, n = 100, 3\n",
        "X = np.random.normal(loc=[-1, 0, 1.5], scale=[1,2,3], size=(m,n))\n",
        "df = pd.DataFrame(X, columns=[f'x{i+1}' for i in range(n)])\n",
        "df['y'] = df.sum(axis=1)\n",
        "\n",
        "# Train Test Split\n",
        "df_train, df_test = train_test_split(df, test_size=0.2)\n",
        "\n",
        "# Isolate the targets\n",
        "y_train = df_train.pop('y')\n",
        "y_test = df_test.pop('y')\n",
        "\n",
        "# Scale\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1), clip=False)\n",
        "df_train_scaled = scaler.fit_transform(df_train)\n",
        "df_test_scaled = scaler.transform(df_test)\n",
        "\n",
        "# Set back to default\n",
        "sklearn.set_config(transform_output='default')\n",
        "\n",
        "df_test_scaled.head()"
      ],
      "metadata": {
        "id": "pl91UNa_gMOt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1a0f150d-8fb5-4dde-9459-dff5cb2bb5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          x1        x2        x3\n",
              "56  0.043290 -0.085371  0.657073\n",
              "9   0.137743 -0.835270  0.062839\n",
              "26  0.338603 -0.134873  0.463875\n",
              "47  0.084565 -1.283132  1.038213\n",
              "35 -0.554816  0.227815  0.349784"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b99c0239-c53f-4ef2-97f7-f8e9c99f4d88\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.043290</td>\n",
              "      <td>-0.085371</td>\n",
              "      <td>0.657073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.137743</td>\n",
              "      <td>-0.835270</td>\n",
              "      <td>0.062839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.338603</td>\n",
              "      <td>-0.134873</td>\n",
              "      <td>0.463875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.084565</td>\n",
              "      <td>-1.283132</td>\n",
              "      <td>1.038213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>-0.554816</td>\n",
              "      <td>0.227815</td>\n",
              "      <td>0.349784</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b99c0239-c53f-4ef2-97f7-f8e9c99f4d88')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b99c0239-c53f-4ef2-97f7-f8e9c99f4d88 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b99c0239-c53f-4ef2-97f7-f8e9c99f4d88');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e08b04dd-94cb-4c07-9cac-a6c65e3fdf53\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e08b04dd-94cb-4c07-9cac-a6c65e3fdf53')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e08b04dd-94cb-4c07-9cac-a6c65e3fdf53 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_scaled",
              "summary": "{\n  \"name\": \"df_test_scaled\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"x1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.37267875123137434,\n        \"min\": -0.9355934314836509,\n        \"max\": 0.7117696570868671,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.043289784071472714,\n          -0.05447997879226024,\n          -0.9355934314836509\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6226818814727048,\n        \"min\": -1.2831315135868921,\n        \"max\": 1.0029464078887993,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.08537070411542032,\n          -0.5728143835012318,\n          0.3497860569740441\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5084622948292681,\n        \"min\": -1.0448946285845704,\n        \"max\": 1.0382134473654228,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.6570725545412904,\n          0.22885693151431663,\n          -0.17874768732356383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Standard Scaler with a sparse matrix\"\"\"\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Data\n",
        "m, n = 1000, 10\n",
        "X = np.random.normal(loc=np.random.randn(n),\n",
        "                     scale=np.random.randint(1, n, size=n),\n",
        "                     size=(m,n))\n",
        "X = np.clip(X, a_min=0, a_max=np.inf).round(2)\n",
        "\n",
        "# Make a sparse matrix\n",
        "sm = csr_matrix(X)\n",
        "\n",
        "# Scale: standerdize without centering\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "sm_scaled = scaler.fit_transform(sm)"
      ],
      "metadata": {
        "id": "tSHfsLPNgQBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Sparse MAtrix (CSR)\"\"\"\n",
        "\n",
        "from IPython.display import Image\n",
        "url = \"https://www.researchgate.net/publication/357418189/figure/fig1/AS:1106555248345089@1640834738634/The-Compressed-Sparse-Row-CSR-format-for-representing-sparse-matrices-provides-a.ppm\"\n",
        "Image(url=url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "fNR_j7MltSjx",
        "outputId": "ab68142c-c133-4fc7-beaf-faf0b8719cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://www.researchgate.net/publication/357418189/figure/fig1/AS:1106555248345089@1640834738634/The-Compressed-Sparse-Row-CSR-format-for-representing-sparse-matrices-provides-a.ppm\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Knn Imputer\"\"\"\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "\n",
        "m = 10\n",
        "n = 3\n",
        "p = 0.25\n",
        "X = np.repeat(list(range(1, m+1)), n).reshape(m,n) * np.logspace(0, n-1, num=n, base=10)\n",
        "x1 = X[:,0].copy()\n",
        "X.ravel()[np.random.permutation(X.size)[:int(m*n*p)]] = np.nan\n",
        "X[:,0] = x1\n",
        "df = pd.DataFrame(X, columns=[f\"x{i+1}\" for i in range(n)])\n",
        "print(df,end=\"\\n\\n\")\n",
        "\n",
        "\n",
        "# Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest = train_test_split(df, test_size=0.2)\n",
        "\n",
        "# KNN Imputer\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=2, weights='uniform')\n",
        "\n",
        "Xtrain_imputed = imputer.fit_transform(Xtrain)\n",
        "Xtrain_imputed = Xtrain_imputed[np.argsort(Xtrain_imputed[:,0])]\n",
        "print(Xtrain_imputed, end=\"\\n\\n\")\n",
        "\n",
        "Xtest_imputed = imputer.transform(Xtest)\n",
        "Xtest_imputed = Xtest_imputed[np.argsort(Xtest_imputed[:,0])]\n",
        "print(Xtest_imputed)"
      ],
      "metadata": {
        "id": "J8F-OQD5QfHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85dc5901-4354-423e-a560-5e719c4a2825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     x1    x2      x3\n",
            "0   1.0  10.0   100.0\n",
            "1   2.0  20.0   200.0\n",
            "2   3.0  30.0   300.0\n",
            "3   4.0  40.0     NaN\n",
            "4   5.0   NaN   500.0\n",
            "5   6.0  60.0   600.0\n",
            "6   7.0  70.0   700.0\n",
            "7   8.0  80.0     NaN\n",
            "8   9.0  90.0   900.0\n",
            "9  10.0   NaN  1000.0\n",
            "\n",
            "[[  1.  10. 100.]\n",
            " [  2.  20. 200.]\n",
            " [  3.  30. 300.]\n",
            " [  4.  40. 400.]\n",
            " [  5.  60. 500.]\n",
            " [  7.  70. 700.]\n",
            " [  8.  80. 600.]\n",
            " [  9.  90. 900.]]\n",
            "\n",
            "[[   6.   60.  600.]\n",
            " [  10.   60. 1000.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Feature Transformation\"\"\"\n",
        "# DO: log(x1/x2);      DON'T: log(x1)/log(x2)\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "from sklearn.pipeline import make_pipeline, make_union\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def get_peaks(a, n_peaks, return_bins=False):\n",
        "    \"\"\"\n",
        "    Finds n_peaks in distribution 'a'\n",
        "    sorted by the peaks height\n",
        "    \"\"\"\n",
        "    for n_bins in range(int(len(a)**(1/2)), 5, -1):\n",
        "        y, x = np.histogram(a, bins=n_bins)\n",
        "        d = np.sign(y[1:] - y[:-1])\n",
        "        d2 = d[1:] - d[:-1]\n",
        "        mask = d2 == -2\n",
        "        if sum(mask) <= n_peaks:\n",
        "            break\n",
        "\n",
        "    # Mask to get the peaks\n",
        "    offset = (len(x)-len(mask)) // 2\n",
        "    mask = [False]*offset + list(mask) + [False]*(len(x)-len(mask)-offset)\n",
        "    try:\n",
        "        idx = np.nonzero(mask)[0]\n",
        "        peaks = (x[idx] + x[idx+1]) / 2\n",
        "    except:\n",
        "        peaks = x[mask]\n",
        "\n",
        "    # Sort the peaks according to height\n",
        "    heights = y[mask[:len(y)]]\n",
        "    idx = np.argsort(heights)\n",
        "    peaks = np.take(peaks, idx)[::-1]\n",
        "\n",
        "    # Return a list or a tuple of lists according to 'return_bins'\n",
        "    return (peaks, n_bins) if return_bins else peaks\n",
        "\n",
        "\n",
        "# Make data\n",
        "np.random.seed(42)\n",
        "m, n = 1000, 2\n",
        "X = np.random.normal(size=(m,n))\n",
        "X[:m//3, 1] = np.random.normal(loc=1.5, scale=0.3, size=m//3)\n",
        "X -= X.min(axis=0) - 1\n",
        "X[:, 0] = np.exp(X[:, 0] / 2)\n",
        "X[:, 1] = np.exp(X[:, 1] / 1.7)\n",
        "df = pd.DataFrame(X, columns=[\"milage\", \"age\"]) # ship's milage / age\n",
        "\n",
        "\n",
        "# Feature transformation and engineering (for EDA only)\n",
        "df[[\"log_milage\", \"log_age\"]] = np.log(df[[\"milage\", \"age\"]])\n",
        "df[\"log_milage_per_year\"] = np.log(df['milage'] / df['age'])\n",
        "\n",
        "peaks = get_peaks(df['age'], n_peaks=2)   #[ 6.9, 23.9]\n",
        "gamma = 0.02   # determined manually / visually\n",
        "df[\"similarity_to_peak_at_7\"] = rbf_kernel(df[['age']], [[peaks[0]]], gamma=gamma)\n",
        "df[\"similarity_to_peak_at_24\"] = rbf_kernel(df[['age']], [[peaks[1]]], gamma=gamma)\n",
        "\n",
        "\n",
        "# Visualize the peaks and Gaussian RBF's\n",
        "axes = df.hist(bins=19, figsize=(10,7))\n",
        "axes[0,1].vlines(peaks, ymin=0, ymax=160, color='k', linewidth=0.5)\n",
        "axes[0,1].scatter(df['age'], df[\"similarity_to_peak_at_7\"] * 160, color='red', s=0.5, alpha=0.6)\n",
        "axes[0,1].scatter(df['age'], df[\"similarity_to_peak_at_24\"] * 120, color='purple', s=0.5, alpha=0.6)\n",
        "\n",
        "\n",
        "# Define Funtion Transformers (for pipeline)\n",
        "log_transformer = FunctionTransformer(np.log, inverse_func=np.exp)\n",
        "ratio_transformer = FunctionTransformer(lambda X: np.log(X[:, [0]] / X[:, [1]]))\n",
        "rbf_transformer = FunctionTransformer(lambda X, Y, gamma: rbf_kernel(X[:, [1]], Y=Y, gamma=gamma),\n",
        "                  kw_args=dict(Y=peaks.reshape(-1,1), gamma=gamma))\n",
        "standard_scaler = FunctionTransformer(lambda X: np.c_[(X[:, :3] - X[:, :3].mean(0)) / X[:, :3].std(0), X[:, 3:]])\n",
        "\n",
        "\n",
        "# Make a preprocessing pipeline\n",
        "fu = make_union(log_transformer, ratio_transformer, rbf_transformer)\n",
        "pl = make_pipeline(fu, standard_scaler)\n",
        "\n",
        "# Pretend this is our train set\n",
        "X_train = df[['milage', 'age']].values\n",
        "\n",
        "# Put the data set trhough the transformation pipline\n",
        "X_transformed = pl.fit_transform(X_train)\n",
        "\n",
        "# Visualize\n",
        "pd.DataFrame(X_transformed, columns=[\"log_milage\", \"log_age\", \"log_milage_per_year\", \"similarity_to_peak_at_7\", \"similarity_to_peak_at_24\"]).hist(bins=30, figsize=(10,7));\n"
      ],
      "metadata": {
        "id": "I7ZjujvWSGAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### CUSTOM TRANSFORMER AND PY-TESTS FOR IT ###\n",
        "\n",
        "\"\"\"\n",
        "The name of this file is assumed to 'test_this_file.py' (for pytest's sake')\n",
        "\n",
        "TO RUN THE TESTS (SEE BELOW) DO:\n",
        "$ cd thisfolder; pytest\n",
        "or:\n",
        "$ pytest thisfolder/test_this_file.py\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils.validation import check_array, check_is_fitted\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "\n",
        "class MyStandardScaler(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, with_mean=True):  # no *args, **kwargs !\n",
        "        self.with_mean = with_mean\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_names_in_ = list(X.columns) if isinstance(X, pd.DataFrame) else None\n",
        "        X = check_array(X)\n",
        "        self.mean_ = X.mean(axis=0)\n",
        "        self.std_ = X.std(axis=0)\n",
        "        self.n_features_in_ = X.shape[1]\n",
        "        return self\n",
        "\n",
        "    def get_feature_names_out(self):\n",
        "        return self.feature_names_in_\n",
        "\n",
        "    def _validate(self, X):\n",
        "        check_is_fitted(self)\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            if list(X.columns) != self.feature_names_in_:\n",
        "                raise ValueError(\"Column names must match\")\n",
        "            X = pd.DataFrame(check_array(X), columns=X.columns)\n",
        "        else:\n",
        "            X = check_array(X)\n",
        "\n",
        "        if self.n_features_in_ != X.shape[1]:\n",
        "            raise ValueError(\"n_features do not match\")\n",
        "        return X\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = self._validate(X)\n",
        "\n",
        "        if self.with_mean:\n",
        "            X = X - self.mean_\n",
        "\n",
        "        return X / self.std_\n",
        "\n",
        "    def inverse_transform(self, X):\n",
        "        X = self._validate(X)\n",
        "        X = X * self.std_\n",
        "        return X + self.mean_ if self.with_mean else X\n",
        "\n",
        "\n",
        "\n",
        "##### PY-TESTS #####\n",
        "# the name of this file is 'test_this_file.py'\n",
        "\n",
        "import pytest\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "\n",
        "# Make data\n",
        "m, n = 10, 5\n",
        "ls = np.random.binomial(n=10, p=0.5, size=(m,n)).tolist()\n",
        "X = nd = np.array(ls)\n",
        "\n",
        "# FIXTURES\n",
        "@pytest.fixture\n",
        "def X_fixture():\n",
        "    return nd\n",
        "\n",
        "@pytest.fixture\n",
        "def df_fixture():\n",
        "    return pd.DataFrame(X,  columns=[f\"x{i}\" for i in range(n)])\n",
        "\n",
        "@pytest.fixture\n",
        "def scaler_fixture():\n",
        "    return MyStandardScaler()\n",
        "\n",
        "\n",
        "# TESTS\n",
        "def test_has_attribute(scaler_fixture):\n",
        "    assert hasattr(scaler_fixture, 'fit_transform')\n",
        "\n",
        "def test_accepts_lists():\n",
        "    tr = MyStandardScaler().fit(ls)  # this must not raise an error\n",
        "    tr.transform(ls)                 # and this must not raise an error either\n",
        "\n",
        "@pytest.mark.filterwarnings(\"ignore\")\n",
        "def test_outputs_dataframe(scaler_fixture, df_fixture):\n",
        "    scaler_fixture.fit(df_fixture)\n",
        "    output = scaler_fixture.transform(df_fixture)\n",
        "    assert isinstance(output, pd.DataFrame), \"My Test: The output must be a df\"\n",
        "\n",
        "@pytest.mark.filterwarnings(\"ignore\")\n",
        "def test_identical_feature_names(scaler_fixture, df_fixture):\n",
        "    tr = scaler_fixture.fit(df_fixture)\n",
        "    df_transformed = tr.transform(df_fixture)\n",
        "    df_inverse = tr.inverse_transform(df_transformed)\n",
        "    assert list(tr.feature_names_in_) == list(df_transformed.columns), \"TODO\"\n",
        "    assert list(tr.feature_names_in_) == list(df_inverse.columns), \"TODO\"\n",
        "\n",
        "@pytest.mark.filterwarnings(\"ignore\")\n",
        "def test_get_feature_names_out(scaler_fixture, df_fixture):\n",
        "    scaler_fixture.fit(df_fixture)\n",
        "    assert list(df_fixture.columns) == list(scaler_fixture.get_feature_names_out())\n",
        "\n",
        "def test_inverse_transform(scaler_fixture, X_fixture):\n",
        "    tr = scaler_fixture\n",
        "    X_inv = tr.inverse_transform(tr.fit_transform(X_fixture))\n",
        "    assert np.allclose(X_inv, X_fixture), \"The input X must be np.allclose to the output of the 'inverse_transform' method\"\n",
        "\n",
        "def test_with_mean(scaler_fixture):\n",
        "    tr = scaler_fixture\n",
        "    tr.fit(X)\n",
        "    X_transformed = tr.transform(X)\n",
        "    assert np.allclose(X_transformed.mean(0), 0)\n",
        "\n",
        "def test_without_mean(X_fixture):\n",
        "    means = (X_fixture / X_fixture.std(0)).mean(0)\n",
        "    tr = MyStandardScaler(with_mean=False)\n",
        "    tr.fit(X_fixture)\n",
        "    X_transformed = tr.transform(X_fixture)\n",
        "    assert np.allclose(means, X_transformed.mean(axis=0))\n",
        "\n",
        "def test_n_features_match(scaler_fixture, X_fixture):\n",
        "    tr = scaler_fixture.fit(X_fixture)\n",
        "    bad_input = np.c_[X_fixture, X_fixture[:, [0]]]\n",
        "    with pytest.raises(ValueError):\n",
        "        tr.transform(bad_input)\n"
      ],
      "metadata": {
        "id": "V7GmAryZk0qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"COLUMN TRANSFROMER (drop, passthrough, remainder)\"\"\"\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "from string import ascii_uppercase\n",
        "\n",
        "# make data\n",
        "m, n = 100, 10\n",
        "df = pd.DataFrame(np.random.normal(size=(m,n)), columns=[f\"x{i+1}\" for i in range(n)]).round(2)\n",
        "df.iloc[:, 3:5] = (pd.DataFrame(np.random.binomial(n=25, p=[0.01, 0.99], size=(m,2)))\n",
        "                     .applymap(lambda x: ascii_uppercase[x]))  #'applymap' is depricated, use 'map'\n",
        "df.iloc[:, 6:9] = np.nan\n",
        "\n",
        "\n",
        "# DEMO ON COLUMN-TRANSFROMER\n",
        "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
        "from sklearn.compose import (ColumnTransformer,\n",
        "                             make_column_transformer,\n",
        "                             make_column_selector)\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy='median')),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "\n",
        "cat_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'),\n",
        "                             OneHotEncoder(drop=None,\n",
        "                                           handle_unknown='ignore',\n",
        "                                           sparse_output=False))\n",
        "\n",
        "# Make a Column Transformer out of the two pipelines\n",
        "ct = make_column_transformer(\n",
        "        (num_pipeline, make_column_selector(dtype_include=np.number)),\n",
        "        (cat_pipeline, make_column_selector(dtype_include=object))\n",
        "    )\n",
        "\n",
        "# ...or like this:\n",
        "ct = ColumnTransformer([\n",
        "        (\"pipeline_1\", num_pipeline, [0, 1, 2]),   # use indeces\n",
        "        (\"pipeline_2\", cat_pipeline, make_column_selector(dtype_include=object)),\n",
        "        (\"pass\", 'passthrough', ['x6']),           # or column names\n",
        "        (\"drop\", 'drop', slice(6, 9, None))\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "\n",
        "X_tr = ct.fit_transform(df)\n",
        "df_tr = pd.DataFrame(X_tr, columns=ct.get_feature_names_out())\n",
        "\n",
        "print(df_tr.columns)\n",
        "ct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "6q7AjvfqL3Kl",
        "outputId": "e9f3c29c-5444-4e4d-caea-2f6961a71dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['pipeline_1__x1', 'pipeline_1__x2', 'pipeline_1__x3',\n",
            "       'pipeline_2__x4_A', 'pipeline_2__x4_B', 'pipeline_2__x4_C',\n",
            "       'pipeline_2__x5_X', 'pipeline_2__x5_Y', 'pipeline_2__x5_Z', 'pass__x6',\n",
            "       'remainder__x10'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ColumnTransformer(remainder='passthrough',\n",
              "                  transformers=[('pipeline_1',\n",
              "                                 Pipeline(steps=[('imputer',\n",
              "                                                  SimpleImputer(strategy='median')),\n",
              "                                                 ('scaler', StandardScaler())]),\n",
              "                                 [0, 1, 2]),\n",
              "                                ('pipeline_2',\n",
              "                                 Pipeline(steps=[('simpleimputer',\n",
              "                                                  SimpleImputer(strategy='most_frequent')),\n",
              "                                                 ('onehotencoder',\n",
              "                                                  OneHotEncoder(handle_unknown='ignore',\n",
              "                                                                sparse_output=False))]),\n",
              "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x78e76c082860>),\n",
              "                                ('pass', 'passthrough', ['x6']),\n",
              "                                ('drop', 'drop', slice(6, 9, None))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
              "                  transformers=[(&#x27;pipeline_1&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 [0, 1, 2]),\n",
              "                                (&#x27;pipeline_2&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                 (&#x27;onehotencoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                sparse_output=False))]),\n",
              "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x78e76c082860&gt;),\n",
              "                                (&#x27;pass&#x27;, &#x27;passthrough&#x27;, [&#x27;x6&#x27;]),\n",
              "                                (&#x27;drop&#x27;, &#x27;drop&#x27;, slice(6, 9, None))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
              "                  transformers=[(&#x27;pipeline_1&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 [0, 1, 2]),\n",
              "                                (&#x27;pipeline_2&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                 (&#x27;onehotencoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                sparse_output=False))]),\n",
              "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x78e76c082860&gt;),\n",
              "                                (&#x27;pass&#x27;, &#x27;passthrough&#x27;, [&#x27;x6&#x27;]),\n",
              "                                (&#x27;drop&#x27;, &#x27;drop&#x27;, slice(6, 9, None))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline_1</label><div class=\"sk-toggleable__content\"><pre>[0, 1, 2]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline_2</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x78e76c082860&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pass</label><div class=\"sk-toggleable__content\"><pre>[&#x27;x6&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>slice(6, 9, None)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;x10&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"COLUMN TRANSFORMER\"\"\"\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def make_ratio_pipline():\n",
        "    return make_pipeline(\n",
        "        SimpleImputer(strategy='median'),\n",
        "        FunctionTransformer(lambda X: X[:, [0]] / X[:, [1]],\n",
        "                            feature_names_out=lambda self, feature_names_in: [\"ratio\"]),\n",
        "        StandardScaler())\n",
        "\n",
        "\n",
        "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, hyperparameter=None):\n",
        "        self.hyperparameter = hyperparameter\n",
        "    def fit(self, X, y=None):\n",
        "        self.n_features_ = X.shape[1]\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return np.c_[X**2, X**3]\n",
        "    def get_feature_names_out(self, feature_names_in=None):\n",
        "        return [f\"custom_transformer_{i+1}\" for i in range(self.n_features_ * 2)]\n",
        "\n",
        "\n",
        "custom_transformer_pipeline = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy='mean')),\n",
        "        (\"transformer\", CustomTransformer()),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "\n",
        "log_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='median'),\n",
        "    FunctionTransformer(np.log, feature_names_out='one-to-one'),\n",
        "    StandardScaler()\n",
        ")\n",
        "\n",
        "cat_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='most_frequent'),\n",
        "    OneHotEncoder(handle_unknown='ignore')\n",
        ")\n",
        "\n",
        "num_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='median'),\n",
        "    StandardScaler()\n",
        ")\n",
        "\n",
        "# Construct a Column Transformer\n",
        "processing = ColumnTransformer([\n",
        "    (\"x1_per_x2\", make_ratio_pipline(), ['x1', 'x2']),\n",
        "    (\"x1_per_x3\", make_ratio_pipline(), ['x1', 'x3']), # use column names,\n",
        "    (\"custom\", custom_transformer_pipeline, [0,1,2]),  # indeces\n",
        "    (\"log\", log_pipeline, slice(0, 3)),                # or slices\n",
        "    (\"cat\", cat_pipeline, make_column_selector(dtype_include=object))\n",
        "],\n",
        "    remainder=num_pipeline)\n",
        "\n",
        "# Make data\n",
        "def make_data():\n",
        "    rs = np.random.RandomState(100)\n",
        "    m, n = 100, 6\n",
        "    X = rs.binomial(n=25, p=rs.random(size=n), size=(m,n))\n",
        "    df = pd.DataFrame(X, columns=[f\"x{i+1}\" for i in range(n)])\n",
        "    df.iloc[:, 3:5] = df.iloc[:, 3:5].applymap(lambda x: chr(65+x))  # appylmap is depricated\n",
        "    idx = rs.permutation(m*n)[:int(0.1 * n * m)]\n",
        "    for ix in idx:\n",
        "        if ix % n: # skips the last column\n",
        "            df.iloc[ix//n, (ix%n)-1] = np.nan  # do not use pd.NA !!!\n",
        "    return df\n",
        "\n",
        "# Demo\n",
        "df = make_data()\n",
        "X_processed = processing.fit_transform(df)\n",
        "df_processed = pd.DataFrame(X_processed, columns=processing.get_feature_names_out())\n",
        "df_processed.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9h8LTIvL318",
        "outputId": "57d15184-5549-4eea-a6a8-a83476eb41bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['x1_per_x2__ratio', 'x1_per_x3__ratio', 'custom__custom_transformer_1',\n",
              "       'custom__custom_transformer_2', 'custom__custom_transformer_3',\n",
              "       'custom__custom_transformer_4', 'custom__custom_transformer_5',\n",
              "       'custom__custom_transformer_6', 'log__x1', 'log__x2', 'log__x3',\n",
              "       'cat__x4_R', 'cat__x4_S', 'cat__x4_T', 'cat__x4_U', 'cat__x4_V',\n",
              "       'cat__x4_W', 'cat__x4_X', 'cat__x4_Y', 'cat__x4_Z', 'cat__x5_A',\n",
              "       'cat__x5_B', 'remainder__x6'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"PIPELINE WITH CACHING\"\"\"\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random, numpy as np\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "\n",
        "def make_data():\n",
        "    seed = 42\n",
        "    random.seed(seed)\n",
        "    rs = np.random.RandomState(seed=seed)\n",
        "\n",
        "    m, n = 10, 2\n",
        "    min_power, max_power = 2, 5\n",
        "    n_poly_features = n * max_power\n",
        "\n",
        "    X = rs.normal(loc=2, scale=1.0, size=(m,n)).clip(0.1, np.inf)\n",
        "\n",
        "    powers = [tuple(int(e) for e in str(x).zfill(n)) for x in range(min_power, max_power * 10**(n-1) + 1)]\n",
        "    powers = [t for t in powers if min_power <= sum(t) <= max_power]\n",
        "    random.shuffle(powers)\n",
        "    powers = powers[:n_poly_features]\n",
        "\n",
        "    poly_features = np.vstack([np.multiply.reduce(X ** p, axis=1) for p in powers]).T\n",
        "    weights = rs.normal(loc=0, scale=10, size=n_poly_features)\n",
        "    y = (poly_features * weights).sum(axis=1)\n",
        "    y = (y - y.min()).round(4)  # simulate adding a bias and errors\n",
        "    return X,y\n",
        "\n",
        "# Make data\n",
        "X,y = make_data()\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "#########################################################################\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "        (\"poly\", PolynomialFeatures()),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"lasso\", Lasso())\n",
        "    ], memory='cache')\n",
        "\n",
        "param_grid = [\n",
        "        {'poly__degree': [2, 3], 'lasso__alpha': [0.01, 0.1]},\n",
        "        {'poly__degree': [4, 5, 6], 'lasso__alpha': [0.1, 1.0, 10]},\n",
        "    ]\n",
        "gs = GridSearchCV(estimator=pipeline, param_grid=param_grid,\n",
        "                  scoring='neg_root_mean_squared_error',\n",
        "                  cv=LeaveOneOut(),\n",
        "                  refit=True,\n",
        "                  verbose=1)\n",
        "gs.fit(Xtrain, ytrain)\n",
        "\n",
        "# Demo\n",
        "ypred = gs.best_estimator_.predict(Xtest)\n",
        "print(f\"ytrue: {ytest.round(2)}\\nypred: {ypred.round(2)}\\nerror: {-round(gs.best_score_,2)}\")\n",
        "print(f\"best parameters: {gs.best_params_}\")\n"
      ],
      "metadata": {
        "id": "s_fltTicL3te",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed52b700-86ee-4d05-d2ef-47d2480c8eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 8 folds for each of 13 candidates, totalling 104 fits\n",
            "ytrue: [4464.03 4650.49]\n",
            "ypred: [4476.94 4682.73]\n",
            "error: 90.05\n",
            "best parameters: {'lasso__alpha': 1.0, 'poly__degree': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ENSEMBLE MODEL FOR REGRESSION ###\n",
        "\n",
        "\"\"\"\n",
        "ENSEMBLE MODEL FOR REGRESSION\n",
        "\n",
        "Regression Ensebmle model\n",
        "- make a preprocessing pipeline (impute, transform, scale)\n",
        "- train test split\n",
        "- select 2 promising estimators out of 3 (lin, random_forest, knn)\n",
        "- tune hypeporameters with rand-grid-search\n",
        "- adjust model weights according to the respective R-squareds (?)\n",
        "- unite into a Voting Regressor\n",
        "- test on  the test set\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from scipy.stats import randint\n",
        "from sklearn.preprocessing import (OrdinalEncoder,\n",
        "                                   OneHotEncoder,\n",
        "                                   FunctionTransformer,\n",
        "                                   StandardScaler)\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "from sklearn.base import clone\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def make_data():\n",
        "    m, n = 1000, 2\n",
        "    p = 0.05  # proportion of nans\n",
        "    seed = 42\n",
        "    rs = np.random.RandomState(seed)\n",
        "\n",
        "    X = rs.normal(scale=1.0, size=(m,n))\n",
        "    X_poly = np.c_[X, X ** 2 * [1, -1]]\n",
        "\n",
        "    weights = rs.normal(size=4)\n",
        "    weights[2:] = np.abs(weights[2:])  # for saddle\n",
        "\n",
        "    y = (X_poly * weights).sum(axis=1)\n",
        "\n",
        "    # add categorical variable\n",
        "    cat = rs.binomial(n=2, p=0.5, size=m)\n",
        "    y += cat * y.std()\n",
        "    y = (y - y.min() + 1.0)\n",
        "\n",
        "    # transform X\n",
        "    X = np.exp(X - X.min(axis=0) + 1.0)\n",
        "\n",
        "    # make df\n",
        "    df = pd.DataFrame(np.c_[X, cat, y], columns=[\"x1\", \"x2\", \"x3\", \"y\"])\n",
        "    df['x3'] = pd.Categorical(df['x3'].astype(np.uint8), ordered=True)\n",
        "    df.x3 = df.x3.cat.rename_categories([\"S\", \"M\", \"L\"])\n",
        "\n",
        "    # nans\n",
        "    idx = rs.permutation(df.size)[:int(p * df.size)]\n",
        "    for ix in idx:\n",
        "        df.iloc[ix // df.shape[1], ix % df.shape[1]] = np.nan\n",
        "    return df\n",
        "\n",
        "\n",
        "# get data\n",
        "df = make_data()\n",
        "\n",
        "# drop rows if nan in the target\n",
        "df.dropna(subset=['y'], inplace=True)\n",
        "\n",
        "# isolate the target\n",
        "X, y = df.iloc[:, :-1], df['y']\n",
        "\n",
        "# Train Test Split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Linear Regression Pipeline\n",
        "pl_lin = make_pipeline(ColumnTransformer([\n",
        "            (\"num\",\n",
        "             make_pipeline(\n",
        "                     SimpleImputer(strategy='median'),\n",
        "                     FunctionTransformer(np.log, inverse_func=np.exp),\n",
        "                     StandardScaler()\n",
        "                 ),\n",
        "             make_column_selector(dtype_include=np.number)),\n",
        "\n",
        "            (\"cat\",\n",
        "             make_pipeline(\n",
        "                     SimpleImputer(strategy='most_frequent'),\n",
        "                     OneHotEncoder(drop='first', handle_unknown='ignore')\n",
        "                 ),\n",
        "             make_column_selector(dtype_include=[object, 'category']))\n",
        "                                        ]),\n",
        "            LinearRegression()\n",
        "    )\n",
        "\n",
        "# KNN Regression Pipeline\n",
        "pl_knn = clone(pl_lin)\n",
        "pl_knn.steps[0][1].transformers[1][1].steps[1][1].drop = None\n",
        "pl_knn.steps[-1] = ('knn', KNeighborsRegressor())\n",
        "\n",
        "# Random Forest Regressor Pipeline\n",
        "pl_rf = make_pipeline(ColumnTransformer([\n",
        "            (\"num\", SimpleImputer(strategy='median'), make_column_selector(dtype_include=np.number)),\n",
        "            (\"cat\",\n",
        "             make_pipeline(\n",
        "                     SimpleImputer(strategy='most_frequent'),\n",
        "                     OrdinalEncoder(categories=[['S', 'M', 'L']], handle_unknown='error')\n",
        "                 ),\n",
        "             make_column_selector(dtype_include=[object, 'category']))\n",
        "                                        ]),\n",
        "            RandomForestRegressor()\n",
        "    )\n",
        "\n",
        "# Select two promising models\n",
        "for i, model in enumerate([pl_lin, pl_knn, pl_rf]):\n",
        "    errors = -cross_val_score(estimator=model, X=Xtrain, y=ytrain,\n",
        "                             cv=3, scoring='neg_root_mean_squared_error')\n",
        "    rsq = cross_val_score(estimator=model, X=Xtrain, y=ytrain,\n",
        "                          cv=3, scoring='r2')\n",
        "    print(f\"model{i+1}: errors = {errors.round(2)} \\t R² = {rsq.round(2)}\")\n",
        "\n",
        "# based on the results above we select KNN and RandomForest\n",
        "models = [pl_knn, pl_rf]\n",
        "\n",
        "# Random HP Search\n",
        "hp_search_knn = GridSearchCV(pl_knn,\n",
        "       {\n",
        "            'knn__n_neighbors': [1,3,5],\n",
        "            'knn__weights': ['uniform', 'distance'],\n",
        "        },\n",
        "        cv=3, scoring='neg_root_mean_squared_error')\n",
        "hp_search_knn.fit(X,y)\n",
        "md_knn = hp_search_knn.best_estimator_\n",
        "\n",
        "hp_search_rf = RandomizedSearchCV(pl_rf,\n",
        "        {\n",
        "           'randomforestregressor__criterion': ['squared_error', 'absolute_error'],\n",
        "           'randomforestregressor__max_depth': randint(10, 100),\n",
        "        },\n",
        "            n_iter=10, cv=3, scoring='neg_root_mean_squared_error')\n",
        "hp_search_rf.fit(X,y)\n",
        "md_rf = hp_search_rf.best_estimator_\n",
        "\n",
        "\n",
        "# Error Analysis\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, sharey=True, figsize=(10,3))\n",
        "\n",
        "ytrue = ytrain\n",
        "ypred = md_knn.predict(Xtrain)\n",
        "residuals = ytrue - ypred\n",
        "residuals = (residuals - residuals.mean()) / residuals.std()\n",
        "ax1.plot(ypred, residuals, 'k.', markersize=3)\n",
        "ax1.set_title(\"KNN Residual Plot\")\n",
        "ax1.set_xlabel(\"predicted values\")\n",
        "ax1.set_ylabel(\"normalized residuals\")\n",
        "\n",
        "ypred = md_rf.predict(Xtrain)\n",
        "residuals = ytrue - ypred\n",
        "residuals = (residuals - residuals.mean()) / residuals.std()\n",
        "ax2.plot(ypred, residuals, 'k.', markersize=3)\n",
        "ax2.set_title(\"RF Residual Plot\")\n",
        "ax2.set_xlabel(\"predicted values\")\n",
        "ax2.set_ylabel(None)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Measure R² for model weights\n",
        "rsq_knn = cross_val_score(estimator=md_knn, X=Xtrain, y=ytrain,\n",
        "                      cv=3, scoring='r2').mean()\n",
        "\n",
        "rsq_rf = cross_val_score(estimator=md_rf, X=Xtrain, y=ytrain,\n",
        "                      cv=3, scoring='r2').mean()\n",
        "model_weights = np.array([rsq_knn, rsq_rf]) / np.array([rsq_knn, rsq_rf]).sum()\n",
        "\n",
        "\n",
        "# Make a Voting Regressor ensemble\n",
        "ensebmle = VotingRegressor(estimators=[(\"knn\", md_knn), (\"rf\", md_rf)],\n",
        "                           weights=model_weights)\n",
        "\n",
        "# Estimate the generalization error\n",
        "ensebmle.fit(Xtrain, ytrain)\n",
        "ypred = ensebmle.predict(Xtest)\n",
        "\n",
        "rsq = ensebmle.score(Xtest, ytest)  # 93%\n",
        "rmse = mean_squared_error(ytest, ypred) ** 0.5\n",
        "print(f\"Ensemble on test-set: R² = {round(rsq,2)} \\t RMSE = {round(rmse,2)}\")\n",
        "\n",
        "# Dissect the RF\n",
        "md_rf['randomforestregressor'].feature_importances_"
      ],
      "metadata": {
        "id": "i9oLr8XZk64y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "06855438-c5e4-4677-cb7c-a2d18ada754d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model1: errors = [1.25 1.32 0.98] \t R² = [0.42 0.4  0.59]\n",
            "model2: errors = [0.72 0.65 0.54] \t R² = [0.81 0.86 0.88]\n",
            "model3: errors = [0.62 0.62 0.46] \t R² = [0.86 0.87 0.91]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble on test-set: R² = 0.93 \t RMSE = 0.41\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.51245247, 0.16958982, 0.31795771])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FAST API\n",
        "\n",
        "\"\"\"\n",
        "main.py\n",
        "$ pip install \"fastapi[all]\"\n",
        "$ uvicorn main:app --reload\n",
        "http://127.0.0.1:8000/redoc\n",
        "\n",
        "POST requests in the bash console:\n",
        "\n",
        "curl \\\n",
        "  --header \"Content-Type: application/json\" \\\n",
        "  --request POST \\\n",
        "  --data '{\"x1\": \"1.25\", \"x2\": \"1\"}' \\\n",
        "  http://localhost:8000/predict\n",
        "\n",
        "or like this:\n",
        "\n",
        "curl -X 'POST' \\\n",
        "  'http://127.0.0.1:8000/predict' \\\n",
        "  -H 'accept: aplication/json' \\\n",
        "  -H 'Content-Type: application/json' \\\n",
        "  -d '{\n",
        "    \"x1\": 1.75,\n",
        "    \"x2\": 0,\n",
        "    \"x3\": \"small\"\n",
        "    }'\n",
        "\n",
        "FastAPI tutorial:\n",
        "https://fastapi.tiangolo.com/tutorial/\n",
        "\"\"\"\n",
        "\n",
        "import uvicorn  # not needed if  $ uvicorn main:app\n",
        "from fastapi import FastAPI\n",
        "from fastapi.responses import HTMLResponse\n",
        "from pydantic import BaseModel\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import joblib\n",
        "\n",
        "\n",
        "# Load your model\n",
        "joblib.dump(LinearRegression().fit([[1.0, 0],[2.0, 1],[3.0, 1]], [0.1, 2.5, 3.0]), \"model.pkl\")\n",
        "model = joblib.load(\"model.pkl\")\n",
        "\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "\n",
        "class Data(BaseModel):\n",
        "    x1: float\n",
        "    x2: int\n",
        "    x3: str | None = None\n",
        "\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(data: Data):\n",
        "    d = data.dict()\n",
        "    ypred, = model.predict([[d['x1'], d['x2']]])\n",
        "    return {'prediction': ypred}\n",
        "\n",
        "\n",
        "@app.get(\"/predict\", response_class=HTMLResponse)\n",
        "async def predict(x1: float, x2: float, x3: str = None):\n",
        "    \"\"\"http://127.0.0.1:8000/predict?x1=-7.25&x2=1\"\"\"\n",
        "    ypred, = model.predict([[x1, x2]])\n",
        "    return HTMLResponse(f\"Our prediction: {ypred}\")\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return HTMLResponse(\"Hello World\")\n",
        "\n",
        "\n",
        "@app.get(\"/items/{item_id}\")\n",
        "def get_item(item_id: int):\n",
        "    return {'item_id': item_id}\n",
        "\n",
        "\n",
        "@app.get(\"/users/{user_id}/items/{item_id}\")\n",
        "async def get_user_item(user_id: int,\n",
        "                         item_id: str,\n",
        "                         q: str | None = None):\n",
        "    \"\"\"http://127.0.0.1:8000/users/123/items/bookshelf?q=title:%22The%20Book%22%20AND%20author:%22M.Wright%22\"\"\"\n",
        "    return {\"user_id\": user_id, \"item_id\": item_id, \"q\": q}\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    uvicorn.run(app, host='127.0.0.1', port=8000)\n",
        "# or bash: $ uvicorn main:app --reload\n"
      ],
      "metadata": {
        "id": "r2KdxG7Rk61S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIDENCE INTERVAL FOR RMSE\n",
        "from math import sqrt\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "# given\n",
        "ytest = [10.5, 12.1, 14.0, 11.0, 7.8, 8.1, 9.2]\n",
        "ypred = [10.6, 12.0, 14.1, 11.1, 7.7, 8.0, 9.1]\n",
        "\n",
        "# erros\n",
        "e = np.array(ytest) - ypred\n",
        "\n",
        "# squared errors\n",
        "es = e ** 2\n",
        "\n",
        "# select alpha\n",
        "α = 0.95\n",
        "\n",
        "# calculate q\n",
        "q = (1 + α) / 2\n",
        "\n",
        "# compute t (not z - because the test set is too small)\n",
        "n = len(e)\n",
        "t = stats.t.ppf(q, df=n-1) #ppf = inverse cdf\n",
        "z = stats.norm.ppf(q)      # z-score (if n is large enough)\n",
        "\n",
        "# calculate SEM\n",
        "sd = es.std(ddof=1)\n",
        "sem = sd / sqrt(n)\n",
        "\n",
        "# calculate the margin (squared)\n",
        "M = t * sem   # bzw z*sem\n",
        "\n",
        "# calculate the CI\n",
        "x = sum(es) / n  # average squared error\n",
        "CI = [sqrt(x-M), sqrt(x+M)]\n",
        "\n",
        "# with scipy\n",
        "mean = mean(es)\n",
        "sem = stats.sem(es)\n",
        "CI = np.sqrt(stats.t.interval(confidence=α, df=n-1, loc=mean, scale=sem))\n",
        "print(f\"The {α*100:.0f}% confidence interval for the RMSE = {CI}\")"
      ],
      "metadata": {
        "id": "_Y1HR6r5k6y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffee19a-4a3c-4178-bf79-d447cd14635d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confidence interval = [0.09999999999999963, 0.09999999999999964]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEMPLATE CLASSIFIER\n",
        "from sklearn.base import ClassifierMixin, BaseEstimator\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import euclidean_distances\n",
        "\n",
        "\n",
        "class TemplateClassifier(ClassifierMixin, BaseEstimator):\n",
        "    \"\"\"Template Classifier\"\"\"\n",
        "    def __init__(self, *, threshold=0.5):\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X, y = check_X_y(X, y)  # Check that X and y have correct shape\n",
        "        self.classes_ = unique_labels(y)\n",
        "        self.X_, self.y_ = X,y\n",
        "        self.is_fitted = True\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = check_array(X)\n",
        "        return ...\n",
        "\n",
        "    def predict(self, X):\n",
        "        idx = np.argmin(euclidean_distances(X, self.X_), axis=1)\n",
        "        return self.y_[idx]"
      ],
      "metadata": {
        "id": "lEwM8DK0k6wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# POISSON REGRESSION\n",
        "from sklearn.linear_model import PoissonRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np, pandas as pd\n",
        "import warnings\n",
        "np.set_printoptions(suppress=True)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Make data\n",
        "def make_data():\n",
        "    m, n = 24*60, 3\n",
        "    x1 = np.repeat(np.linspace(0, 1, num=m), 7)\n",
        "    x2 = np.random.random(size=len(x1))\n",
        "    x3 = np.random.choice([0,1], p=(0.9, 0.1), size=len(x1))\n",
        "    x0 = np.ones(shape=len(x1))\n",
        "    X = np.c_[x0, x1, x2, x3]\n",
        "\n",
        "    ww = (np.abs(np.random.normal(loc=0, scale=1, size=n))) * [1, -1, 1]\n",
        "    ww = np.array([3, *ww])\n",
        "\n",
        "    y = np.multiply.reduce(np.exp(X * ww), axis=1).round().astype(int)\n",
        "    df = pd.DataFrame(np.c_[X[:,1:], y], columns=[\"time\", \"price\", \"event\", \"count\"])\n",
        "    return df, ww\n",
        "\n",
        "# Get data\n",
        "df, weights = make_data()\n",
        "X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
        "\n",
        "# Split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Model\n",
        "md = PoissonRegressor(alpha=0.0, fit_intercept=True)\n",
        "md.fit(Xtrain, ytrain)\n",
        "\n",
        "# Weights\n",
        "print(\"ground truth weights:\", list(weights.round(3)))\n",
        "print(\"learned weights:\", list(np.array([md.intercept_, *md.coef_]).round(3)))\n",
        "\n",
        "# Estimate the generalization error\n",
        "rsq = md.score(Xtest, ytest)\n",
        "print(\"R² on test-set:\", rsq.round(4))"
      ],
      "metadata": {
        "id": "REEfWQHDk6ut",
        "outputId": "671dd69c-70de-4ca2-847f-9c51da0ca664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ground truth weights: [3.0, 0.953, -1.674, 0.264]\n",
            "learned weights: [3.001, 0.952, -1.676, 0.264]\n",
            "R² on test-set: 0.9987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# POLYNOMIAL REGRESSION - THE CORRECT WAY\n",
        "\"\"\"\n",
        "standedize\n",
        "poly (poly-expansion will often cause multicoliniarity)\n",
        "ridge / elastic (but not lasso, because it doesn't handle multicoliniarity)\n",
        "\n",
        "Ridge handles multicoliniarity\n",
        "Lasso does variable selection\n",
        "ElasticNet does both\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.linear_model import Ridge, ElasticNet\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "steps = [('scaler', StandardScaler()),\n",
        "         ('poly', PolynomialFeatures(degree=3)),\n",
        "         ('elastic', ElasticNet(alpha=1.0, l1_ratio=0.5))]\n",
        "pipe = Pipeline(steps)"
      ],
      "metadata": {
        "id": "jGev3IjvdOpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM CLASSIFIER\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics import fbeta_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "\n",
        "def make_data(m=100, n=5, return_dataframe=False, random_seed=None):\n",
        "    rs = np.random.RandomState(random_seed)\n",
        "    X = rs.binomial(n=range(n, 0, -1), p=0.5, size=(m,n))\n",
        "    y = X.sum(axis=1) % 2\n",
        "    if return_dataframe:\n",
        "        X,y = pd.DataFrame(X, columns=[f\"x{i+1}\" for i in range(n)]), pd.Series(y)\n",
        "    return X,y\n",
        "\n",
        "\n",
        "# get data\n",
        "X, y = make_data()\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# LightGBM\n",
        "import lightgbm as lgb\n",
        "\n",
        "train_data = lgb.Dataset(Xtrain, label=ytrain, categorical_feature=[3, 4])\n",
        "\n",
        "params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'binary',\n",
        "    'metric': 'average_precision',  # ???\n",
        "    'learning_rate': 0.05,\n",
        "    'verbose': 0}\n",
        "\n",
        "num_round = 100\n",
        "gb = lgb.train(params, train_data, num_round)\n",
        "ypred = gb.predict(Xtest) >= 0.5\n",
        "\n",
        "\n",
        "# LGBMClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# get data\n",
        "X, y = make_data(return_dataframe=True)\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Integrate an LGBMClassifier into sklearn's pipeline\n",
        "pl = make_pipeline(\n",
        "    ColumnTransformer([\n",
        "        (\"num\", 'passthrough', make_column_selector(dtype_include=np.number)),\n",
        "        (\"cat\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), make_column_selector(dtype_include=['category', object]))\n",
        "                ],\n",
        "        remainder='passthrough'),\n",
        "    LGBMClassifier(objective='binary'))\n",
        "\n",
        "params = {f'{pl.steps[-1][0]}__feature_name': list(Xtrain.columns),\n",
        "          f'{pl.steps[-1][0]}__categorical_feature': ['x4', 'x5'],\n",
        "          f'{pl.steps[-1][0]}__eval_metric': 'auc'}\n",
        "\n",
        "pl.fit(Xtrain, ytrain, **params)\n",
        "ypred = pl.predict(Xtest)\n",
        "\n",
        "\n",
        "# Plot feature importances\n",
        "lgb.plot_importance(pl.steps[-1][1], importance_type=\"gain\", figsize=(7,6), title=\"LightGBM Feature Importance\");\n"
      ],
      "metadata": {
        "id": "cEeq8ihrdOmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# THRESHOLD OPTIMIZATION\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, fbeta_score\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "# Get data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit and predict probabilities\n",
        "clf = LogisticRegression().fit(X_train, y_train)\n",
        "probs = clf.predict_proba(X_val)[:, 1]  # Probabilities of class 1\n",
        "\n",
        "# Try all the thresholds\n",
        "f2 = partial(fbeta_score, beta=2)\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "f2_scores = [f2(y_val, (probs > thresh).astype(int)) for thresh in thresholds]\n",
        "\n",
        "best_threshold = thresholds[np.argmax(f2_scores)]\n",
        "best_f2_score = max(f2_scores)\n",
        "print(\"best threshold:\", best_threshold)\n",
        "print(\"best f2-Score:\", best_f2_score)"
      ],
      "metadata": {
        "id": "AvIYq9DMdOjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b97de7-0ace-4216-8931-0a7454094c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best threshold: 0.16161616161616163\n",
            "best f2-Score: 0.8985765124555161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SOFT CLASSIFYING ENSEMBLE WITH UPSAMPLING AND OPTIMIZED THRESHOLD\n",
        "\"\"\"\n",
        "UPSAMPLE OR NOT TO UPSAMPLE THE RARE CLASS:\n",
        "Support Vector:      yes\n",
        "Logistic Regression: yes\n",
        "Tree-based:          only if extreme imbalanced\n",
        "Naive Bayes:         not nececarry, only if extreme imbalanced\n",
        "\n",
        "\n",
        "GOAL: F2\n",
        "- make train val test sets\n",
        "- make a pipeline with upsamping, etc (for NB not cesessary to upsampel (but will not hurt))\n",
        "- cross valscore to select top 3 models based on f2\n",
        "- measure the pairwise distance of the FN sets (the more the better)\n",
        "- grid search HP each classifier\n",
        "- unite into one soft voting classifier\n",
        "- oprimize the threshold of the single voting classsifier for the best F2 on the val set\n",
        "\"\"\"\n",
        "\n",
        "from itertools import combinations\n",
        "import numpy as np, pandas as pd\n",
        "from scipy.stats import norm\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, roc_auc_score, fbeta_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from scipy.stats import loguniform\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "\n",
        "def make_data(m, n, prior=None,\n",
        "              proportion_of_useless_features=None,\n",
        "              proportion_of_nans=None,\n",
        "              random_state=None):\n",
        "    prior = float(prior or 0.5)\n",
        "    proportion_of_useless_features = float(proportion_of_useless_features or 0)\n",
        "    proportion_of_nans = float(proportion_of_nans or 0)\n",
        "    rs = np.random.RandomState(random_state)\n",
        "    X = rs.randn(m,n)\n",
        "    X_ = X[:, :n-int(n*proportion_of_useless_features)]\n",
        "    logits = (X_ * -np.array(range(X_.shape[1], 0, -1))).sum(1)\n",
        "\n",
        "    for q in np.linspace(start=prior, stop=0.99, num=100):\n",
        "        y = logits < np.quantile(logits, q=q)\n",
        "        logs = np.log(norm.pdf(X_)).sum(axis=1)\n",
        "        y &= logs < np.quantile(logs, q=q)\n",
        "        if sum(y) / len(y) >= prior:\n",
        "            break\n",
        "    # introduce nans\n",
        "    X.ravel()[rs.permutation(X.size)[:int(proportion_of_nans*X.size)]] = np.nan\n",
        "    return X, y.astype(int)\n",
        "\n",
        "\n",
        "def train_val_test_split(X, y, stratify=None,\n",
        "                         dataset_proportions=None,\n",
        "                         random_state=None):\n",
        "    stratify = stratify or y\n",
        "    dataset_proportions = dataset_proportions or 0.15\n",
        "    if type(dataset_proportions) is float and 0.1 <= dataset_proportions <= 0.2:\n",
        "        dataset_proportions = (1 - dataset_proportions*2, dataset_proportions, dataset_proportions)\n",
        "    dataset_proportions = np.array(dataset_proportions) / sum(dataset_proportions)\n",
        "    assert sum(dataset_proportions) == 1.0\n",
        "    test_size = dataset_proportions[-1]\n",
        "    val_size = dataset_proportions[1] / (dataset_proportions[0] + dataset_proportions[1])\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=stratify, test_size=test_size, random_state=random_state)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, stratify=y_train_val, test_size=val_size, random_state=random_state)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "\n",
        "def f2(*args):\n",
        "    \"\"\"\n",
        "    Works both as a scorer e.g. for cross_val_score -> implicit signature: (estimator, X, y)\n",
        "    and 'f2_score'  -> implicit signature: (y_true, y_pred)\n",
        "    \"\"\"\n",
        "    if len(args) == 2:\n",
        "        return fbeta_score(*args, beta=2)\n",
        "    est, X, y = args\n",
        "    return fbeta_score(y, est.predict(X), beta=2)\n",
        "\n",
        "\n",
        "def error_sets_difference(y_true, y_pred_a, y_pred_b, error_type=None):\n",
        "    y_true, y_pred_a, y_pred_b = (np.array(a) for a in (y_true, y_pred_a, y_pred_b))\n",
        "\n",
        "    if str(error_type).upper() == 'FN':\n",
        "        a = (y_true == 1) & (y_pred_a == 0)\n",
        "        b = (y_true == 1) & (y_pred_b == 0)\n",
        "\n",
        "    elif str(error_type).upper() == 'FP':\n",
        "        a = (y_true == 0) & (y_pred_a == 1)\n",
        "        b = (y_true == 0) & (y_pred_b == 1)\n",
        "    else:\n",
        "        a = y_true != y_pred_a\n",
        "        b = y_true != y_pred_b\n",
        "\n",
        "    similariry = sum(a & b) / sum(a | b)\n",
        "    return 1 - similariry\n",
        "\n",
        "\n",
        "def make_pipeline(classifier, with_oversampling=True):\n",
        "    steps = [\n",
        "        (\"oversampler\", RandomOverSampler(random_state=random_state)),\n",
        "        (\"imputer\", SimpleImputer(strategy='mean')),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"classifier\", classifier)\n",
        "    ]\n",
        "    return imbpipeline(steps if with_oversampling else steps[1:])\n",
        "\n",
        "\n",
        "# Random seed\n",
        "random_state = 302\n",
        "\n",
        "# Get data\n",
        "X, y = make_data(m=1000, n=20, prior=0.1,\n",
        "                 proportion_of_useless_features=0.25,\n",
        "                 proportion_of_nans=0.01,\n",
        "                 random_state=random_state)\n",
        "\n",
        "# Train Val Test split\n",
        "(X_train, X_val, X_test, y_train, y_val, y_test) = \\\n",
        "    train_val_test_split(X, y, dataset_proportions=(0.65, 0.20, 0.15),\n",
        "                         random_state=random_state)\n",
        "\n",
        "# Classifiers out of which we will select 3 best classifiers\n",
        "nb = GaussianNB()\n",
        "lr = LogisticRegression(penalty='l1', solver='liblinear', C=0.01, random_state=random_state)\n",
        "sv = SVC(kernel='rbf', probability=True, random_state=random_state)\n",
        "rf = RandomForestClassifier(random_state=random_state)\n",
        "\n",
        "# Make pipelines\n",
        "# note: for this particular dataset it turns out that it is better to upsample data for Gaussian Naive Bayes\n",
        "classifiers = (nb, lr, sv, rf)\n",
        "pipelines = [make_pipeline(md, with_oversampling=b)\n",
        "             for md,b in zip(classifiers, [True, True, True, False])]\n",
        "\n",
        "# Cross-val F2-score to select the best classifiers\n",
        "d = dict()\n",
        "for pl in pipelines:\n",
        "    scores = cross_val_score(pl, X_train, y_train, cv=5, scoring=f2)\n",
        "    d[pl[-1].__class__.__name__] = {\"f2\": scores.mean(),\n",
        "                                    \"std\": scores.std(),\n",
        "                                    \"AUC\": roc_auc_score(y_val, pl.fit(X_train, y_train).predict_proba(X_val)[:, -1])}\n",
        "print(pd.DataFrame(d).T.round(2))\n",
        "\n",
        "# Determine how diverse the calssifiers are (pairwise)\n",
        "# in therms of how different the FN mistakes they make\n",
        "print(\"_\"*52 + \"\\n\\n\\nError sets pairwise distances (the more the better):\\n\")\n",
        "for pair in combinations(pipelines, r=2):\n",
        "    a,b = pair\n",
        "    distance = error_sets_difference(y_val, a.predict(X_val), b.predict(X_val),\n",
        "                                     error_type='FN')\n",
        "    print(a[-1].__class__.__name__, \"vs\", b[-1].__class__.__name__, \":\", round(distance,2))\n",
        "\n",
        "# Based on F2-scores we select these three classifiers\n",
        "nb, lr, sv, _ = pipelines\n",
        "\n",
        "# HP Search for Logistic Regression\n",
        "params = {'classifier__penalty': ['l1', 'l2'], 'classifier__C': loguniform(0.001, 10), 'classifier__solver': ['liblinear', 'saga']}\n",
        "lr = RandomizedSearchCV(lr, params, scoring=f2, cv=5, n_iter=50).fit(X_train, y_train).best_estimator_\n",
        "\n",
        "# HP Search for SVC\n",
        "common = {'classifier__C': [0.1, 1, 10], 'classifier__probability': [True]}\n",
        "params = [{'classifier__kernel': ['linear']},\n",
        "          {'classifier__kernel': ['rbf'], 'classifier__gamma': ['scale', 'auto', 1, 0.1, 0.01]},\n",
        "          {'classifier__kernel': ['poly'], 'classifier__gamma': ['scale', 'auto', 1, 0.1, 0.01], 'classifier__degree': [2, 3, 4]}]\n",
        "[d.update(common) for d in params]\n",
        "sv = GridSearchCV(sv, params, scoring=f2, cv=5).fit(X_train, y_train).best_estimator_\n",
        "\n",
        "# Make an ensemble\n",
        "vc = VotingClassifier([(\"nb\", nb), (\"lr\", lr), (\"sv\", sv)], voting='soft')\n",
        "vc.fit(X_train, y_train)\n",
        "\n",
        "# Try all the thresholds\n",
        "probs = vc.predict_proba(X_val)[:, 1]\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "f2_scores = [f2(y_val, (probs > thresh).astype(int)) for thresh in thresholds]\n",
        "best_threshold = thresholds[np.argmax(f2_scores)]\n",
        "best_f2_score = max(f2_scores)\n",
        "print(\"\\n\\nbest threshold:\", round(best_threshold, 2))\n",
        "print(\"best f2-score on the validation set:\", round(best_f2_score, 2))\n",
        "\n",
        "# Test\n",
        "def predict(X):\n",
        "    global best_threshold\n",
        "    return (vc.predict_proba(X)[:, -1] >= best_threshold).astype(np.uint8)\n",
        "\n",
        "y_pred = predict(X_test)\n",
        "f2_score = f2(y_test, y_pred)\n",
        "print(f\"F2 with threshold {round(best_threshold, 2)} on the test set:\", round(f2_score, 2))"
      ],
      "metadata": {
        "id": "U-mb2gGkdOe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed514b0-6244-48af-94d6-18d5e3ee5d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          f2   std   AUC\n",
            "GaussianNB              0.61  0.07  0.90\n",
            "LogisticRegression      0.43  0.05  0.84\n",
            "SVC                     0.34  0.05  0.95\n",
            "RandomForestClassifier  0.06  0.07  0.90\n",
            "____________________________________________________\n",
            "\n",
            "\n",
            "Error sets pairwise distances (the more the better):\n",
            "\n",
            "GaussianNB vs LogisticRegression : 0.67\n",
            "GaussianNB vs SVC : 0.64\n",
            "GaussianNB vs RandomForestClassifier : 0.69\n",
            "LogisticRegression vs SVC : 0.7\n",
            "LogisticRegression vs RandomForestClassifier : 0.81\n",
            "SVC vs RandomForestClassifier : 0.47\n",
            "\n",
            "\n",
            "best threshold: 0.49\n",
            "best f2-score on the validation set: 0.73\n",
            "F2 with threshold 0.49 on the test set: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CROSS_VAL_SCORE WITH AUC\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "def scorer(clf, X, y):\n",
        "    probs = clf.predict_proba(X)[:, 1]\n",
        "    return roc_auc_score(y, probs)\n",
        "\n",
        "\n",
        "# Make data\n",
        "X, y = make_classification(n_samples=10000, n_features=20, n_informative=2,\n",
        "                           n_redundant=10, n_classes=2, n_clusters_per_class=1,\n",
        "                           weights=[0.99, 0.01], flip_y=0.01, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the classifier\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Define the cross-validation strategy (equivelent to cv=5)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation with AUC scoring\n",
        "scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring=scorer)"
      ],
      "metadata": {
        "id": "Ehro0dNOwFqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPELINE WITH OVERSAMPLING\n",
        "import warnings\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
        "\n",
        "\n",
        "def make_data(m=10000, n=4, prior=0.01, random_state=None):\n",
        "    rs = np.random.RandomState(random_state)\n",
        "    df = pd.DataFrame(rs.binomial(n=range(n, 0, -1), p=rs.random(n), size=(m,n)), columns=[f\"x{i+1}\" for i in range(n)])\n",
        "    df.iloc[:, :2] += rs.normal(scale=df.iloc[:, :2].std(axis=0), size=(m,2))\n",
        "    logits = df.sum(axis=1)\n",
        "    df['y'] = (logits >= np.quantile(logits, q=1-prior)).astype(np.uint8)\n",
        "    df.iloc[:, :2] -= df.iloc[:, :2].min(axis=0) + 0.01\n",
        "    df.iloc[:, :2] = (df.iloc[:, :2].abs() ** [2, 3]).round(6)\n",
        "    df[['x3', 'x4']] = df[['x3', 'x4']].astype('category')\n",
        "    df['x3'] = df.x3.cat.rename_categories([f\"{chr(65+i)}\" for i in range(len(set(df['x3'])))]).astype(str)\n",
        "    return df\n",
        "\n",
        "\n",
        "# Get data\n",
        "random_state = 42\n",
        "df = make_data(random_state=random_state)\n",
        "df.info()\n",
        "X, y = df, df.pop('y')\n",
        "\n",
        "# Train Test split\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "\n",
        "def make_ratio_pipline(imputer_strategy='mean', log=False):\n",
        "    steps = [\n",
        "        (\"imputer\", SimpleImputer(strategy=imputer_strategy)),\n",
        "        (\"ratio\", FunctionTransformer(lambda X: X[:, [0]] / X[:, [1]], feature_names_out=lambda self, feature_names_in: [\"ratio\"])),\n",
        "        (\"log\", FunctionTransformer(np.log, inverse_func=np.exp, feature_names_out=lambda self, feature_names_in: [\"log\"])),\n",
        "        (\"scaler\", StandardScaler())]\n",
        "    if not log:\n",
        "        del steps[-2]\n",
        "    return Pipeline(steps)\n",
        "\n",
        "\n",
        "# Pipeline for numerical features with right-skewed distributions\n",
        "num_pipline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy='median')),  # because the numerical features are right skewed\n",
        "    (\"log\", FunctionTransformer(np.log, inverse_func=np.exp, feature_names_out=lambda self, feature_names_in: [\"log\"])),   # comment out if necessary\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "# Pipeline for categorical features to put trhough Logisticregression\n",
        "cat_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='most_frequent'),\n",
        "    OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
        "    )\n",
        "\n",
        "\n",
        "steps = [\n",
        "    (\"oversampler\", RandomOverSampler(random_state=random_state)),\n",
        "\n",
        "    (\"transformer\",\n",
        "        ColumnTransformer([\n",
        "            (\"ratio\", make_ratio_pipline(imputer_strategy='median', log=True), [0, 1]),\n",
        "            (\"num\", num_pipline, make_column_selector(dtype_include=np.number)),\n",
        "            (\"cat\", cat_pipeline, make_column_selector(dtype_include=['category', object]))\n",
        "                    ],\n",
        "                remainder='passthrough'),\n",
        "    ),\n",
        "\n",
        "    (\"classifier\", LogisticRegression(penalty='l2', C=1.0, solver='liblinear', random_state=random_state))\n",
        "]\n",
        "\n",
        "# Fit, cross-validate\n",
        "pl = ImbPipeline(steps).fit(X_train, y_train)\n",
        "scores = cross_val_score(pl, X_train, y_train, cv=5, scoring='f1')"
      ],
      "metadata": {
        "id": "UIoj4DBFwFm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff318eb-b39a-4f09-d782-421c15509213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype   \n",
            "---  ------  --------------  -----   \n",
            " 0   x1      10000 non-null  float64 \n",
            " 1   x2      10000 non-null  float64 \n",
            " 2   x3      10000 non-null  object  \n",
            " 3   x4      10000 non-null  category\n",
            " 4   y       10000 non-null  uint8   \n",
            "dtypes: category(1), float64(2), object(1), uint8(1)\n",
            "memory usage: 254.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXTENSIVE PIPELINE WITH UPSAMPLING VS CLASS_WEIGHT\n",
        "\"\"\"\n",
        "UPSAMPLE OR NOT TO UPSAMPLE THE RARE CLASS:\n",
        "Support Vector:      yes (alternative: class_weight)\n",
        "Logistic Regression: yes (alternative: class_weight)\n",
        "Tree-based:          only if extreme imbalanced (alternative: class_weight)\n",
        "Naive Bayes:         not nececarry, only if extremly imbalanced\n",
        "\n",
        "PIPELINE:\n",
        "- impute\n",
        "- upsample (with RandomOverSampler if all numerical otherwise SMOTENC)\n",
        "- encode (one-hot or oridnal): categorical pipeline\n",
        "- transform (e.g. log if long right-hand tail)\n",
        "- standerdize (to make the data normally distributed)\n",
        "- ratio (if necessary)\n",
        "- interactions (bewtwen the numericalfeatures, one-hot-encoded features and inbetween them)\n",
        "- polynomial expansion of the numericla features\n",
        "- ridge classifier\n",
        "- hyperparameter search for F1, F2 or AUC?\n",
        "- unite the clasifiers into a soft voting classifier ensemble\n",
        "- threshold optimize the ensemble for F2 (split the X_train further to make an X_val)\n",
        "\"\"\"\n",
        "\n",
        "import warnings\n",
        "from functools import partial\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
        "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
        "\n",
        "\n",
        "def make_data(m=1000, prior=0.1, nans=0.01, random_state=None):\n",
        "    rs = np.random.RandomState(random_state)\n",
        "    df = pd.DataFrame(rs.randn(m, 3), columns=[\"x1\", \"x2\", \"x3\"])\n",
        "    df[\"x4\"] = rs.choice([\"S\", \"M\", \"L\"], size=m)\n",
        "    df[\"x5\"] = pd.Categorical(rs.randint(1, 6, size=m))\n",
        "    X = pd.get_dummies(df, columns=['x4', 'x5'], drop_first=True, dtype=float)\n",
        "    X = PolynomialFeatures(degree=3, include_bias=False).fit_transform(X)\n",
        "    ratio = df['x1'] / df['x2']\n",
        "    X = np.c_[np.ones(m), ratio.values, X]\n",
        "    w = np.linspace(0, 1, num=X.shape[1])[::-1]\n",
        "    logits = (X * w).sum(1)\n",
        "    y = (logits >= np.quantile(logits, 1-prior)).astype(int)\n",
        "    df.iloc[:, :3] = np.exp(df.iloc[:, :3])\n",
        "    for ix in rs.permutation(df.size)[:int(df.size *nans)]:\n",
        "        i,j = divmod(ix, df.shape[1])\n",
        "        df.iloc[i,j] = np.nan\n",
        "    df['y'] = y\n",
        "    return df\n",
        "\n",
        "\n",
        "class RatioFeatures(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, ratios=[]):\n",
        "        self.ratios = ratios\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.n_features_in_ = X.shape[1]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        m = len(X)\n",
        "\n",
        "        # if df, then columns are int's or str's?\n",
        "        if type(X) is pd.DataFrame:\n",
        "            if set(type(e) for e in sum((tuple(e) for e in self.ratios), ())) == {int}:\n",
        "                X = X.iloc\n",
        "            else:\n",
        "                X = X.loc\n",
        "        # Make ratios\n",
        "        ratios = [X[:, numerator] / X[:, denominator] for numerator, denominator in self.ratios]\n",
        "\n",
        "        # if ratios==[]\n",
        "        ratios = np.c_[*ratios] if len(ratios) else [[]]*m\n",
        "\n",
        "        # return as ndarray or as a df?\n",
        "        if type(X) is np.ndarray:\n",
        "            return ratios\n",
        "        return pd.DataFrame(ratios, columns=self.get_feature_names_out())\n",
        "\n",
        "    def get_feature_names_out(self, feature_names_in=None):\n",
        "        if feature_names_in is None:\n",
        "            return [f\"ratio_{numerator}/{denominator}\" for numerator, denominator in self.ratios]\n",
        "        if self.n_features_in_ != len(feature_names_in):\n",
        "            raise ValueError(\"inconsistent number of features\")\n",
        "        return [f\"ratio_{feature_names_in[numerator]}/{feature_names_in[denominator]}\"\n",
        "                for numerator, denominator in self.ratios]\n",
        "\n",
        "\n",
        "# Get data\n",
        "random_state = None\n",
        "df = make_data(m=1000, random_state=random_state)\n",
        "X, y = df, df.pop('y')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=random_state)\n",
        "input_features = X_train.columns\n",
        "\n",
        "\n",
        "# Build a big pipeline\n",
        "imputer = ColumnTransformer([\n",
        "    (\"num\", SimpleImputer(strategy='median'), [0,1,2]),\n",
        "    (\"cat\", SimpleImputer(strategy='most_frequent'), [3,4])\n",
        "    ])\n",
        "\n",
        "upsampler = SMOTENC(categorical_features=[3, 4], sampling_strategy='auto', k_neighbors=5, random_state=random_state)\n",
        "\n",
        "\n",
        "num_pipeline = make_pipeline(\n",
        "    FunctionTransformer(func=np.log,\n",
        "                        feature_names_out=lambda self, input_features: [f\"log({name})\"for name in input_features],\n",
        "                        validate=True, check_inverse=False),\n",
        "    StandardScaler())\n",
        "\n",
        "cat_pipeline = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, [0, 1, 2]),\n",
        "    (\"cat\", cat_pipeline, [3,4])])\n",
        "\n",
        "\n",
        "union = FeatureUnion([\n",
        "    (\"ratio\", RatioFeatures(ratios=[(0, 1), (1,1)])),\n",
        "    (\"poly\", PolynomialFeatures(degree=3, include_bias=False))])\n",
        "\n",
        "\n",
        "classifier = LogisticRegression(solver='newton-cg', penalty='l2', max_iter=900, random_state=random_state)\n",
        "\n",
        "pl = ImbPipeline([(\"imputer\", imputer),\n",
        "                  (\"upsampler\", upsampler),\n",
        "                  (\"preprocessor\", preprocessor),\n",
        "                  (\"union\", union),\n",
        "                  (\"classifier\", classifier)])\n",
        "\n",
        "# Fit\n",
        "pl.fit(X_train, y_train)\n",
        "\n",
        "# HP search: pl.get_params().keys()\n",
        "parameter_names = pl.get_params().keys()\n",
        "\n",
        "params = {'imputer__num__strategy': ['mean', 'median'],\n",
        "          'upsampler__k_neighbors': [3, 5],\n",
        "          'preprocessor__num__functiontransformer__func': [np.log, lambda x: x],\n",
        "          'union__ratio__ratios': [[(0,1)], [(1,0)], [(0,1), (0,2)], [(0,1), (0,2), (1,2)]],\n",
        "          'union__poly__degree': [1, 2, 3],\n",
        "          'classifier__C': [10, 1, 0.1]}\n",
        "\n",
        "gs = GridSearchCV(pl, params, scoring='roc_auc', cv=5)\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "# HP search results\n",
        "best_estimator = gs.best_estimator_\n",
        "best_params = gs.best_params_\n",
        "best_auc = gs.best_score_\n",
        "print(\"best AUC with upsampling:\", best_auc)\n",
        "\n",
        "\n",
        "# make a df with parameters and scores\n",
        "d = gs.cv_results_['params'].copy()\n",
        "\n",
        "[d.update({\"auc\": round(auc,3), \"std\": std})\n",
        " for (d, auc, std) in zip(d, gs.cv_results_['mean_test_score'], gs.cv_results_['std_test_score'])]\n",
        "\n",
        "# explore the results to choose the optimal model\n",
        "res = pd.DataFrame(d).sort_values(by=['auc', 'std'], ascending=[False, True]).head(10)\n",
        "\n",
        "\n",
        "\n",
        "### A SECOND CLASSIFIER:  class_weight='balanced' without upsampling\n",
        "steps = pl.steps\n",
        "del steps[1]\n",
        "pl2 = Pipeline(steps)\n",
        "pl2[-1].class_weight = 'balanced'\n",
        "params.pop('upsampler__k_neighbors')\n",
        "\n",
        "gs = GridSearchCV(pl2, params, scoring='roc_auc', cv=5).fit(X_train, y_train)\n",
        "\n",
        "# HP search results\n",
        "best_estimator_2 = gs.best_estimator_\n",
        "best_params_2 = gs.best_params_\n",
        "best_auc_2 = gs.best_score_\n",
        "print(\"best AUC with class weight:\", best_auc_2)\n",
        "\n",
        "\n",
        "# Make an ensebmble\n",
        "vc = VotingClassifier(estimators=[(\"upsampling\", best_estimator), (\"class_weights\", best_estimator_2)],\n",
        "                      voting='soft', weights=(0.5, 0.5))\n",
        "\n",
        "# Threshold optimization\n",
        "X_dev, X_val, y_dev, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2, random_state=random_state)\n",
        "vc.fit(X_dev, y_dev)\n",
        "\n",
        "probs = vc.predict_proba(X_val)[:, 1]\n",
        "f2 = partial(fbeta_score, beta=2)\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "f2_scores = [f2(y_val, (probs > thresh).astype(int)) for thresh in thresholds]\n",
        "\n",
        "best_threshold = thresholds[np.argmax(f2_scores)]\n",
        "best_f2_score = max(f2_scores)\n",
        "\n",
        "\n",
        "# Test for F2 on the test set\n",
        "y_pred = vc.predict_proba(X_test)[:, 1] >= best_threshold\n",
        "f2_score_on_test = f2(y_test, y_pred)\n",
        "print(\"F2 on the test set:\", f2_score_on_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "zJ4Lvr8gwFkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COLUMN DROPPER\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Make data\n",
        "random_state = 42\n",
        "rs = np.random.RandomState(random_state)\n",
        "m, n = 10, 5\n",
        "X = rs.binomial(n=range(n, 0, -1), p=0.5, size=(m,n))\n",
        "df = pd.DataFrame(X, columns=[f\"x{i+1}\" for i in range(n)])\n",
        "\n",
        "# Define features to keep and drop\n",
        "num_features = [0, 1, 2]\n",
        "cat_features = [3, 4]\n",
        "drop_features = [0, 4]\n",
        "\n",
        "\n",
        "\n",
        "def make_column_dropper(columns, drop=None):\n",
        "    def closure(X, *args, **kwargs):\n",
        "        nonlocal columns, drop\n",
        "        return [e for e in columns if e not in drop] if drop is not None else columns\n",
        "    return closure\n",
        "\n",
        "\n",
        "cat_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'))\n",
        "\n",
        "num_pipeline = make_pipeline(SimpleImputer(strategy='mean'))\n",
        "\n",
        "transformer = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, make_column_dropper(num_features, drop_features)),\n",
        "        (\"cat\", cat_pipeline, make_column_dropper(cat_features, drop_features)),\n",
        "    ], remainder='drop')\n",
        "\n",
        "\n",
        "w = transformer.fit_transform(df)"
      ],
      "metadata": {
        "id": "LSKYmbE2wFh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"randomized PCA + random forest + param search\"\"\"\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "# get the data\n",
        "X, y = make_decision_tree_data(200, n=100, k=3)\n",
        "\n",
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                          stratify=y, random_state=42)\n",
        "\n",
        "# make a pipeline\n",
        "pipe = make_pipeline(\n",
        "        PCA(svd_solver='randomized'),\n",
        "        RandomForestClassifier(criterion='gini', max_depth=None,\n",
        "                               min_samples_split=2, min_samples_leaf=1, )\n",
        "    )\n",
        "\n",
        "# parameters distributions\n",
        "params = {'pca__n_components': range(2, 100),\n",
        "          'randomforestclassifier__n_estimators': range(20, 200)}\n",
        "\n",
        "# instantiate a randomized seach object\n",
        "rs = RandomizedSearchCV(estimator=pipe, param_distributions=params,\n",
        "                        n_iter=100, cv=5, error_score='raise')\n",
        "\n",
        "# run the search\n",
        "rs.fit(X_train, y_train)\n",
        "\n",
        "# report\n",
        "print(rs.best_params_)\n",
        "\n",
        "best = rs.best_estimator_\n",
        "acc_train = best.score(X_train, y_train)\n",
        "acc_test = best.score(X_test, y_test)\n",
        "print(acc_train, acc_test)"
      ],
      "metadata": {
        "id": "qeSystJMwFfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Incremental PCA\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA, IncrementalPCA\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# get the data\n",
        "bunch = fetch_openml('mnist_784', as_frame=False)\n",
        "X, y = bunch.data, bunch.target\n",
        "\n",
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                          stratify=y, random_state=42)\n",
        "# define pca\n",
        "pca = PCA(svd_solver='randomized')       # not this one\n",
        "pca = IncrementalPCA(n_components=200)   # we need incremental PCA\n",
        "\n",
        "# simualte online learning\n",
        "for X_batch in tqdm(np.array_split(X_train, 100)):  # 100 = n_batches\n",
        "    pca.partial_fit(X_batch)\n",
        "\n",
        "\n",
        "# or with a memory map\n",
        "# write the data to a binary file\n",
        "filename = \"x_train.mmap\"\n",
        "mm = np.memmap(filename, dtype=X.dtype, mode='write', shape=X_train.shape)\n",
        "mm[:] = X_train\n",
        "mm.flush()\n",
        "\n",
        "# make a memory-map to read the binary file\n",
        "mm = np.memmap(filename, dtype=X.dtype, mode='readonly').reshape(*X_train.shape)\n",
        "\n",
        "# instantiate an Incremental PCA\n",
        "n_batches = 100\n",
        "batch_size = mm.shape[0] // n_batches\n",
        "pca = IncrementalPCA(n_components=200, batch_size=batch_size)\n",
        "\n",
        "# do PCA incrementally\n",
        "pca.fit(mm)\n",
        "\n",
        "# transform the test set, and then restore it back\n",
        "X_reduced = pca.transform(X_test)\n",
        "X_restored = pca.inverse_transform(X_reduced)\n",
        "print(\"shape of X_reduced:\", X_reduced.shape, \"\\nshape of X_restored\", X_restored.shape)\n",
        "\n",
        "# vizualize the cumulative variance\n",
        "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
        "d = np.argmax(cumsum >= 0.95) + 1   # d << n\n",
        "\n",
        "plt.plot(*zip(*enumerate(cumsum)))\n",
        "plt.plot(d, 0.95, 'r.')\n",
        "plt.title(\"Explained variance as a function of the number of dimensions\\n\"\n",
        "          f\"{d} principle components give us 95% of variance\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xIkinf3owFdG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "972a7eef-a3b3-4de2-feac-bd9af8c4302b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n",
            "100%|██████████| 100/100 [00:50<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of X_reduced: (14000, 200) \n",
            "shape of X_restored (14000, 784)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Custom Class for partial_fit\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class IncrementalPipeline(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, transformer, classifier):\n",
        "        self.transformer = transformer\n",
        "        self.classifier = classifier\n",
        "\n",
        "    def partial_fit(self, X, y, classes=None):\n",
        "        if not hasattr(self, 'classes_'):\n",
        "            self.classes_ = classes\n",
        "\n",
        "        self.transformer.partial_fit(X)\n",
        "        X_transformed = self.transformer.transform(X)\n",
        "        self.classifier.partial_fit(X_transformed, y, classes=self.classes_)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_transformed = self.transformer.transform(X)\n",
        "        return self.classifier.predict(X_transformed)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X_transformed = self.transformer.transform(X)\n",
        "        return self.classifier.predict_proba(X_transformed)\n",
        "\n",
        "\n",
        "# get the data\n",
        "bunch = fetch_openml('mnist_784', as_frame=False)\n",
        "X, y = bunch.data, bunch.target\n",
        "y = [int(c) for c in y]\n",
        "classes = sorted(set(y))\n",
        "\n",
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                          stratify=y, random_state=42)\n",
        "# instantiate incremental pipeline\n",
        "pca = IncrementalPCA(n_components=154)  # 154 : 95%\n",
        "sgd = SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001)\n",
        "pipe = IncrementalPipeline(transformer=pca, classifier=sgd)\n",
        "\n",
        "# simualte online learning (100 batches)\n",
        "n_batches = 100\n",
        "for X_batch, y_batch in tqdm(zip(np.array_split(X_train, n_batches),\n",
        "                                 np.array_split(y_train, n_batches))):\n",
        "    pipe.partial_fit(X_batch, y_batch, classes=classes)\n",
        "\n",
        "# asses\n",
        "acc_train = pipe.score(X_train, y_train)\n",
        "acc_test = pipe.score(X_test, y_test)\n",
        "print(\"train / test accuracy:\", acc_train, acc_test)"
      ],
      "metadata": {
        "id": "5wqwmFW5wFar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ItTMsK0wFYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cmwihom3dOcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BoU547Dqk6sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: PANEL REGRESSION\n",
        "# https://medium.com/pew-research-center-decoded/using-fixed-and-random-effects-models-for-panel-data-in-python-a795865736ab\n",
        "# https://towardsdatascience.com/a-guide-to-panel-data-regression-theoretics-and-implementation-with-python-4c84c5055cf8"
      ],
      "metadata": {
        "id": "ATWnbYqJGHtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P9jRVrMlGHou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nsVO6HxMGHmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0LkRfqlrk6iy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}